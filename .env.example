# LLM Provider Configuration
# Choose which LLM to use for inference (chat/reasoning)
# Options: "openai", "groq", or "deepseek"
LLM_PROVIDER=openai

# OpenAI Configuration (for inference)
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4o

# Groq Configuration (RECOMMENDED: Fast & cheap with function calling!)
# Get your API key from: https://console.groq.com
# Model options: openai/gpt-oss-20b (recommended), llama-3.1-70b-versatile
GROQ_API_KEY=your_groq_api_key_here
GROQ_MODEL=openai/gpt-oss-20b
GROQ_BASE_URL=https://api.groq.com/openai/v1

# DeepSeek Configuration (NOT RECOMMENDED: function calling issues)
# Get your API key from: https://platform.deepseek.com
DEEPSEEK_API_KEY=your_deepseek_api_key_here
DEEPSEEK_MODEL=deepseek-chat
DEEPSEEK_BASE_URL=https://api.deepseek.com

# ChromaDB Configuration
CHROMA_PERSIST_DIR=./chroma_db
CHROMA_COLLECTION_NAME=ti_datasheets

# Application Configuration
BACKEND_HOST=0.0.0.0
BACKEND_PORT=8000
FRONTEND_URL=http://localhost:3000

# LangGraph Configuration
LANGCHAIN_TRACING_V2=false
LANGCHAIN_API_KEY=

# Embedding Model
# Option 1: OpenAI (recommended for best quality, ~$0.02 per 1M tokens)
EMBEDDING_MODEL=openai/text-embedding-3-small
# Option 2: Local sentence-transformers (free, good quality)
# EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
