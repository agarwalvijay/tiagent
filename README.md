# TI Semiconductor Product Finder Agent

An intelligent agent for finding and recommending semiconductor products (chips, SoCs, analog chips, dev boards) based on specifications and use cases.

## ğŸ¯ Features

- **ğŸ” Semantic Search**: Find products based on natural language descriptions
- **ğŸ¯ Specification Filtering**: Exact matching on voltage, frequency, temperature, peripherals
- **ğŸ¤– LangGraph Agent**: Intelligent orchestration with proactive clarification questions
- **ğŸ’¬ Multi-turn Conversations**: Maintains context across queries
- **ğŸ“Š Comparison Mode**: Side-by-side comparison of multiple chips
- **ğŸ”„ Alternative Finding**: Find substitutes and alternatives
- **ğŸ—ï¸ Application Recommendations**: Get complete solutions for specific use cases
- **ğŸ“š 28 TI Datasheets**: Pre-loaded with real Texas Instruments datasheets

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   User Interface                     â”‚
â”‚              React + TypeScript Chat UI              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ REST API
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 FastAPI Backend                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚          LangGraph Agent (GPT-4o)            â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚  Tools:                                â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  - Semantic Search                     â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  - Filtered Search                     â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  - Compare Parts                       â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  - Recommend for Use Case              â”‚  â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  ChromaDB (Vector DB)  â”‚
         â”‚  - 500+ chunks         â”‚
         â”‚  - Metadata filtering  â”‚
         â”‚  - Semantic embeddings â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ Tech Stack

**Backend:**
- Python 3.11
- FastAPI (REST API)
- LangGraph (Agent orchestration)
- OpenAI GPT-4o (LLM)
- ChromaDB (Vector database)
- sentence-transformers (Embeddings)
- PyMuPDF + pdfplumber (PDF parsing)

**Frontend:**
- React 18 + TypeScript
- React Markdown (Message rendering)
- Axios (API client)

## ğŸš€ Quick Start

See **[QUICKSTART.md](QUICKSTART.md)** for detailed setup instructions.

### TL;DR

```bash
# 1. Add OpenAI API key to .env
echo "OPENAI_API_KEY=sk-your-key" > .env

# 2. Run setup (10-15 minutes)
./setup.sh

# 3. Start backend (terminal 1)
./run_backend.sh

# 4. Start frontend (terminal 2)
./run_frontend.sh

# 5. Open http://localhost:3000
```

## ğŸ“– Example Queries

**Find by Specifications:**
```
"Find a 32-bit MCU with USB and ADC under 3.3V"
"I need a low-power chip with I2C and SPI that works at -40Â°C"
"Which chips have AI accelerators?"
```

**Compare Parts:**
```
"Compare MSPM0G5187 with MSPM0C1106"
"What's the difference between F28377D-SEP and MSPM0G5187?"
```

**Use Case Recommendations:**
```
"What chips would work for a battery-powered IoT sensor?"
"Recommend an MCU for motor control in automotive applications"
"Best chip for industrial automation at high temperatures"
```

**Technical Details:**
```
"What are the features of MSPM0G5187?"
"How do I configure I2C on the MSPM0G5187?"
"What pins support SPI on the F28377D?"
```

## ğŸ“ Project Structure

```
TI/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py              # FastAPI application
â”‚   â”‚   â””â”€â”€ models.py            # Pydantic models
â”‚   â”œâ”€â”€ parsers/
â”‚   â”‚   â””â”€â”€ pdf_parser.py        # PDF extraction & metadata
â”‚   â”œâ”€â”€ ingestion/
â”‚   â”‚   â””â”€â”€ ingest_datasheets.py # ChromaDB ingestion pipeline
â”‚   â”œâ”€â”€ agent/
â”‚   â”‚   â”œâ”€â”€ graph.py             # LangGraph agent orchestration
â”‚   â”‚   â””â”€â”€ tools.py             # Search tools
â”‚   â””â”€â”€ config.py                # Configuration
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.tsx              # Main application
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â””â”€â”€ ChatMessage.tsx  # Message component
â”‚   â”‚   â””â”€â”€ services/
â”‚   â”‚       â””â”€â”€ api.ts           # API client
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ Datasheets/                  # PDF datasheets (28 files)
â”œâ”€â”€ chroma_db/                   # Vector DB (generated)
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ setup.sh                     # Setup script
â”œâ”€â”€ run_backend.sh              # Start backend
â”œâ”€â”€ run_frontend.sh             # Start frontend
â”œâ”€â”€ .env                        # Environment variables
â””â”€â”€ README.md
```

## ğŸ”§ Advanced Usage

### Adding New Datasheets

Place PDF files in the `Datasheets/` folder and run:

```bash
python3 -m backend.ingestion.ingest_datasheets --datasheet-dir Datasheets
```

### View Database Statistics

```bash
python3 -m backend.ingestion.ingest_datasheets --stats
```

### Health Check

```bash
curl http://localhost:8000/api/health
```

## ğŸ§  How It Works

### 1. PDF Parsing
- Extracts structured metadata (part numbers, specs, architecture)
- Identifies sections (Features, Specifications, Pin Config, etc.)
- Creates semantic chunks optimized for retrieval

### 2. Vector Storage
- Stores chunks in ChromaDB with metadata
- Generates embeddings using sentence-transformers
- Enables hybrid search (semantic + metadata filtering)

### 3. LangGraph Agent
- Classifies user intent (search, compare, recommend, troubleshoot)
- Decides when to ask clarifying questions
- Calls appropriate tools (semantic search, filtered search, comparison)
- Synthesizes responses with citations

### 4. Response Generation
- GPT-4o generates natural language responses
- Cites specific part numbers and specifications
- Explains trade-offs between options

## ğŸ¨ Customization

### Change LLM Model

Edit `.env`:
```bash
OPENAI_MODEL=gpt-4o-mini  # Faster, cheaper
# or
OPENAI_MODEL=gpt-4o       # Default, most capable
```

### Adjust Search Parameters

Edit `backend/agent/tools.py`:
```python
# Increase number of search results
def semantic_search(query: str, top_k: int = 10):  # Was 5
```

### Add New Tools

1. Define tool in `backend/agent/tools.py`
2. Add to `self.tools` list in `backend/agent/graph.py`
3. Update system prompt with tool description

## ğŸ› Troubleshooting

**Issue: "No results found"**
- Run `python3 -m backend.ingestion.ingest_datasheets --stats` to verify data
- Check if ChromaDB is populated: `ls chroma_db/`

**Issue: Slow responses**
- First query is slower (model loading)
- Consider using `gpt-4o-mini` for faster responses
- Check OpenAI API rate limits

**Issue: Backend won't start**
- Verify `.env` has valid `OPENAI_API_KEY`
- Install dependencies: `pip3 install -r requirements.txt`
- Check port 8000 isn't already in use

**Issue: Frontend can't reach backend**
- Ensure backend is running on port 8000
- Check `frontend/src/services/api.ts` has correct URL

## ğŸš€ Deployment (GCP VM)

For production deployment on Google Cloud Platform:

1. **Provision VM**
   - Machine: e2-standard-2 (2 vCPU, 8 GB)
   - OS: Ubuntu 22.04 LTS
   - Firewall: Allow HTTP/HTTPS

2. **Install Dependencies**
   ```bash
   sudo apt update
   sudo apt install python3.11 python3-pip nodejs npm
   ```

3. **Clone and Setup**
   ```bash
   git clone <your-repo>
   cd TI
   ./setup.sh
   ```

4. **Run with systemd**
   Create service files for backend and frontend
   (examples in `deployment/` folder if needed)

5. **Setup Nginx**
   Use Nginx as reverse proxy for production

## ğŸ“„ License

MIT

## ğŸ¤ Contributing

This is a demonstration project. For production use:
- Add authentication
- Implement Redis for session storage
- Add rate limiting
- Set up monitoring (Prometheus, Grafana)
- Add comprehensive tests

## ğŸ“ Support

For issues or questions:
- Check [QUICKSTART.md](QUICKSTART.md) for setup help
- Review error logs in backend console
- Verify ChromaDB statistics with `--stats` flag
